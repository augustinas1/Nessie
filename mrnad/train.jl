# Train Nessie using the data generated by mrnad/gen.jl
using JLD2

include("../train_NN.jl")
include("model.jl")
include("../viz.jl")

@load joinpath(MODEL_DIR, "train_data.jld2") X_train y_train
@load joinpath(MODEL_DIR, "valid_data.jld2") X_valid y_valid
@load joinpath(MODEL_DIR, "test_data.jld2") X_test y_test

train_data = (X_train, y_train)
valid_data = (X_valid, y_valid)
test_data = (X_test, y_test)

""" Create neural network with the given number of negative binomial components and the specified number of hidden units per layer (one hidden layer should be enough) """
function build_model(n_comps::Int, x::Vector{Int}=[32])
    hidden_layers = [Dense(x[i-1], x[i], relu) for i in 2:length(x)]
    model = Chain(InputLayer(),
                  Dense(1 + numreactionparams(rn), x[1], relu),
                  hidden_layers...,
                  MNBOutputLayer(x[end], n_comps)
            )
    MNBModel(model)
end

# Training
model = build_model(4, [1024])
@time train_losses, valid_losses = train_NN!(model, train_data, valid_data; max_rounds=500, lr=0.001, batchsize=1000)
@save joinpath(MODEL_DIR, "model.jld2") model

# Evaluate predictive performance
println("Training dataset")
println("KLD: ", mean_loss(X_train, y_train, model; loss=loss_kldivergence))
println("Hellinger: ", mean_loss(X_train, y_train, model; loss=loss_hellinger))

println("\nValidation dataset")
println("KLD: ", mean_loss(X_valid, y_valid, model; loss=loss_kldivergence))
println("Hellinger: ", mean_loss(X_valid, y_valid, model; loss=loss_hellinger))

println("\nTest dataset")
println("KLD: ", mean_loss(X_test, y_test, model; loss=loss_kldivergence))
println("Hellinger: ", mean_loss(X_test, y_test, model; loss=loss_hellinger))

# clean memory as it gets hogged up
GC.gc() 
